"""
AutoArchitect - Excel Parser (v2.0 ë¦¬íŒ©í† ë§)
- ExcelParser: ê¸°ë³¸í˜• (LAYERS/COMPONENTS ê¸°ë°˜)
- NestedExcelParser: ê³„ì¸µí˜• (LAYERS/BOXES/COMPONENTS ê¸°ë°˜)
"""

import pandas as pd
from typing import Dict, Any, List, Optional
from abc import ABC, abstractmethod
import io

from utils.constants import (
    EXCEL_SHEETS,
    REQUIRED_COLUMNS,
    VALIDATION_RULES,
    ERROR_MESSAGES,
    WARNING_MESSAGES,
    COLOR_MAP,
    BORDER_COLOR_MAP,
    COMPONENT_STYLES,
    CONNECTION_STYLES,
    LAYOUT_PATTERNS
)


class BaseExcelParser(ABC):
    """ì—‘ì…€ íŒŒì„œ ê¸°ë³¸ í´ë˜ìŠ¤"""

    def __init__(self):
        self.errors: List[str] = []
        self.warnings: List[str] = []
        self.infos: List[str] = []

    def _reset_messages(self):
        """ë©”ì‹œì§€ ì´ˆê¸°í™”"""
        self.errors = []
        self.warnings = []
        self.infos = []

    def read_excel(self, file) -> Dict[str, pd.DataFrame]:
        """ì—‘ì…€ íŒŒì¼ì„ ì½ì–´ ì‹œíŠ¸ë³„ DataFrame ë°˜í™˜"""
        self._reset_messages()
        sheets = {}

        try:
            # íŒŒì¼ íƒ€ì… ì²˜ë¦¬
            if hasattr(file, 'read'):
                file_content = io.BytesIO(file.read())
                file.seek(0)
                excel_file = pd.ExcelFile(file_content)
            else:
                excel_file = pd.ExcelFile(file)

            # ëª¨ë“  ì‹œíŠ¸ ì½ê¸°
            for sheet_name in excel_file.sheet_names:
                if sheet_name == EXCEL_SHEETS['GUIDE']:
                    continue

                df = pd.read_excel(excel_file, sheet_name=sheet_name)
                df = df.dropna(how='all')
                sheets[sheet_name] = df

            return sheets

        except Exception as e:
            self.errors.append(ERROR_MESSAGES['file_read_error'].format(error=str(e)))
            return {}

    def _get_validation_result(self) -> Dict[str, Any]:
        """ê²€ì¦ ê²°ê³¼ ë°˜í™˜"""
        return {
            'is_valid': len(self.errors) == 0,
            'errors': self.errors,
            'warnings': self.warnings,
            'infos': self.infos
        }

    def _parse_config(self, df: pd.DataFrame) -> Dict[str, Any]:
        """CONFIG ì‹œíŠ¸ íŒŒì‹±"""
        config = {}
        for _, row in df.iterrows():
            key = row.get('í•­ëª©')
            value = row.get('ê°’')
            if pd.notna(key):
                config[key] = value
        return config

    def _parse_connections(self, df: pd.DataFrame) -> List[Dict]:
        """CONNECTIONS ì‹œíŠ¸ íŒŒì‹±"""
        connections = []
        for _, row in df.iterrows():
            if pd.isna(row.get('ì¶œë°œID')) or pd.isna(row.get('ë„ì°©ID')):
                continue

            conn = {
                'from_id': row['ì¶œë°œID'],
                'to_id': row['ë„ì°©ID'],
                'type': row.get('ì—°ê²°íƒ€ì…', 'ë°ì´í„°íë¦„'),
                'label': row.get('ë¼ë²¨', ''),
                'style': row.get('ì„ ìŠ¤íƒ€ì¼', 'ì‹¤ì„ ')
            }
            connections.append(conn)
        return connections

    def _parse_groups(self, df: pd.DataFrame) -> List[Dict]:
        """GROUPS ì‹œíŠ¸ íŒŒì‹±"""
        groups = []
        for _, row in df.iterrows():
            if pd.isna(row.get('ê·¸ë£¹ID')):
                continue

            group = {
                'id': row['ê·¸ë£¹ID'],
                'name': row.get('ê·¸ë£¹ëª…', ''),
                'component_ids': [
                    cid.strip()
                    for cid in str(row.get('í¬í•¨ì»´í¬ë„ŒíŠ¸(IDs)', '')).split(',')
                    if cid.strip()
                ],
                'border_style': row.get('í…Œë‘ë¦¬ìŠ¤íƒ€ì¼', 'ê²€ì •ì‹¤ì„ '),
                'bg_opacity': row.get('ë°°ê²½íˆ¬ëª…ë„', '5%')
            }
            groups.append(group)
        return groups

    @abstractmethod
    def validate_data(self, sheets: Dict[str, pd.DataFrame]) -> Dict[str, Any]:
        """ë°ì´í„° ê²€ì¦ (ì„œë¸Œí´ë˜ìŠ¤ì—ì„œ êµ¬í˜„)"""
        pass

    @abstractmethod
    def parse_to_dict(self, sheets: Dict[str, pd.DataFrame]) -> Dict[str, Any]:
        """ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜ (ì„œë¸Œí´ë˜ìŠ¤ì—ì„œ êµ¬í˜„)"""
        pass


class ExcelParser(BaseExcelParser):
    """ê¸°ë³¸í˜• ì—‘ì…€ íŒŒì„œ (LAYERS/COMPONENTS ê¸°ë°˜)"""

    def validate_data(self, sheets: Dict[str, pd.DataFrame]) -> Dict[str, Any]:
        """ê¸°ë³¸í˜• ë°ì´í„° ê²€ì¦"""
        if self.errors:
            return self._get_validation_result()

        if not sheets:
            self.errors.append(ERROR_MESSAGES['no_sheets_found'])
            return self._get_validation_result()

        # í•„ìˆ˜ ì‹œíŠ¸ í™•ì¸
        required = ['CONFIG', 'LAYERS', 'COMPONENTS']
        for sheet in required:
            if sheet not in sheets:
                self.errors.append(ERROR_MESSAGES['missing_sheet'].format(sheet_name=sheet))

        if self.errors:
            return self._get_validation_result()

        # ì •ë³´ ë©”ì‹œì§€
        self.infos.append("âœ… ê¸°ë³¸í˜• ì—‘ì…€ í˜•ì‹ (LAYERS/COMPONENTS)")

        # LAYERS ê²€ì¦
        self._validate_layers(sheets.get('LAYERS'))

        # COMPONENTS ê²€ì¦
        self._validate_components(sheets.get('COMPONENTS'), sheets.get('LAYERS'))

        # SUB_COMPONENTS ê²€ì¦
        if 'SUB_COMPONENTS' in sheets:
            self._validate_sub_components(sheets['SUB_COMPONENTS'], sheets.get('COMPONENTS'))

        # CONNECTIONS ê²€ì¦
        if 'CONNECTIONS' in sheets:
            self._validate_connections(sheets['CONNECTIONS'], sheets.get('COMPONENTS'))

        # ê°œìˆ˜ ì •ë³´
        self.infos.append(f"ğŸ—‚ï¸ ë ˆì´ì–´: {len(sheets['LAYERS'])}ê°œ")
        self.infos.append(f"ğŸ“¦ ì»´í¬ë„ŒíŠ¸: {len(sheets['COMPONENTS'])}ê°œ")
        if 'CONNECTIONS' in sheets:
            self.infos.append(f"ğŸ”— ì—°ê²°: {len(sheets['CONNECTIONS'])}ê°œ")

        return self._get_validation_result()

    def _validate_layers(self, df: pd.DataFrame):
        """LAYERS ì‹œíŠ¸ ê²€ì¦"""
        if df is None:
            return

        # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
        for col in REQUIRED_COLUMNS['LAYERS']:
            if col not in df.columns:
                self.errors.append(
                    ERROR_MESSAGES['missing_column'].format(
                        sheet_name='LAYERS', column_name=col
                    )
                )

        # ID ì¤‘ë³µ í™•ì¸
        layer_ids = df['ë ˆì´ì–´ID'].dropna()
        duplicates = layer_ids[layer_ids.duplicated()].unique()
        for dup in duplicates:
            self.errors.append(
                ERROR_MESSAGES['duplicate_id'].format(id_type='ë ˆì´ì–´', id_value=dup)
            )

        # ë†’ì´% í•©ê³„ í™•ì¸
        heights = df['ë†’ì´%'].dropna()
        total = heights.sum()
        tolerance = VALIDATION_RULES['height_percent_tolerance']
        if not (100 - tolerance <= total <= 100 + tolerance):
            self.warnings.append(
                ERROR_MESSAGES['height_sum_error'].format(sum=total, tolerance=tolerance)
            )

        # ìƒ‰ìƒ ìœ íš¨ì„±
        for idx, row in df.iterrows():
            bg_color = row.get('ë°°ê²½ìƒ‰')
            if pd.notna(bg_color) and bg_color not in COLOR_MAP:
                self.errors.append(
                    ERROR_MESSAGES['invalid_value'].format(
                        column_name=f'ë°°ê²½ìƒ‰ (í–‰ {idx + 2})',
                        value=bg_color,
                        allowed=', '.join(COLOR_MAP.keys())
                    )
                )

    def _validate_components(self, df: pd.DataFrame, layers_df: pd.DataFrame):
        """COMPONENTS ì‹œíŠ¸ ê²€ì¦"""
        if df is None:
            return

        # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
        for col in REQUIRED_COLUMNS['COMPONENTS']:
            if col not in df.columns:
                self.errors.append(
                    ERROR_MESSAGES['missing_column'].format(
                        sheet_name='COMPONENTS', column_name=col
                    )
                )

        # ID ì¤‘ë³µ í™•ì¸
        comp_ids = df['ID'].dropna()
        duplicates = comp_ids[comp_ids.duplicated()].unique()
        for dup in duplicates:
            self.errors.append(
                ERROR_MESSAGES['duplicate_id'].format(id_type='ì»´í¬ë„ŒíŠ¸', id_value=dup)
            )

        # ë ˆì´ì–´ID ì°¸ì¡° í™•ì¸
        if layers_df is not None:
            valid_layer_ids = set(layers_df['ë ˆì´ì–´ID'].dropna())
            for idx, row in df.iterrows():
                layer_id = row.get('ë ˆì´ì–´ID')
                if pd.notna(layer_id) and layer_id not in valid_layer_ids:
                    self.errors.append(
                        ERROR_MESSAGES['invalid_reference'].format(
                            ref_type=f"ì»´í¬ë„ŒíŠ¸ {row['ID']}",
                            id_value=layer_id
                        )
                    )

        # íƒ€ì… ìœ íš¨ì„±
        valid_types = list(COMPONENT_STYLES.keys())
        for idx, row in df.iterrows():
            comp_type = row.get('íƒ€ì…')
            if pd.notna(comp_type) and comp_type not in valid_types:
                self.errors.append(
                    ERROR_MESSAGES['invalid_value'].format(
                        column_name=f'íƒ€ì… (í–‰ {idx + 2})',
                        value=comp_type,
                        allowed=', '.join(valid_types)
                    )
                )

        # ê°œìˆ˜ ê²½ê³ 
        if len(df) > VALIDATION_RULES['max_components']:
            self.warnings.append(
                WARNING_MESSAGES['too_many_components'].format(
                    count=len(df),
                    max=VALIDATION_RULES['max_components']
                )
            )

    def _validate_sub_components(self, df: pd.DataFrame, components_df: pd.DataFrame):
        """SUB_COMPONENTS ì‹œíŠ¸ ê²€ì¦"""
        if df is None or components_df is None:
            return

        valid_comp_ids = set(components_df['ID'].dropna())

        for idx, row in df.iterrows():
            parent_id = row.get('ë¶€ëª¨ID')
            if pd.notna(parent_id) and parent_id not in valid_comp_ids:
                self.errors.append(
                    ERROR_MESSAGES['invalid_reference'].format(
                        ref_type='ì„œë¸Œì»´í¬ë„ŒíŠ¸',
                        id_value=parent_id
                    )
                )

    def _validate_connections(self, df: pd.DataFrame, components_df: pd.DataFrame):
        """CONNECTIONS ì‹œíŠ¸ ê²€ì¦"""
        if df is None or components_df is None:
            return

        valid_comp_ids = set(components_df['ID'].dropna())

        for idx, row in df.iterrows():
            from_id = row.get('ì¶œë°œID')
            to_id = row.get('ë„ì°©ID')

            if pd.notna(from_id) and from_id not in valid_comp_ids:
                self.errors.append(
                    ERROR_MESSAGES['invalid_reference'].format(
                        ref_type='ì—°ê²° ì¶œë°œ',
                        id_value=from_id
                    )
                )

            if pd.notna(to_id) and to_id not in valid_comp_ids:
                self.errors.append(
                    ERROR_MESSAGES['invalid_reference'].format(
                        ref_type='ì—°ê²° ë„ì°©',
                        id_value=to_id
                    )
                )

            # ìê¸° ì—°ê²° ê²½ê³ 
            if pd.notna(from_id) and pd.notna(to_id) and from_id == to_id:
                self.warnings.append(
                    WARNING_MESSAGES['self_connection'].format(id=from_id)
                )

        # ì—°ê²° íƒ€ì… ìœ íš¨ì„±
        valid_conn_types = list(CONNECTION_STYLES.keys())
        for idx, row in df.iterrows():
            conn_type = row.get('ì—°ê²°íƒ€ì…')
            if pd.notna(conn_type) and conn_type not in valid_conn_types:
                self.errors.append(
                    ERROR_MESSAGES['invalid_value'].format(
                        column_name=f'ì—°ê²°íƒ€ì… (í–‰ {idx + 2})',
                        value=conn_type,
                        allowed=', '.join(valid_conn_types)
                    )
                )

    def parse_to_dict(self, sheets: Dict[str, pd.DataFrame]) -> Dict[str, Any]:
        """ê¸°ë³¸í˜• ë°ì´í„°ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        result = {
            'config': {},
            'layers': [],
            'components': [],
            'sub_components': [],
            'connections': [],
            'groups': []
        }

        # CONFIG
        if 'CONFIG' in sheets:
            result['config'] = self._parse_config(sheets['CONFIG'])

        # LAYERS
        if 'LAYERS' in sheets:
            result['layers'] = self._parse_layers_data(sheets['LAYERS'])

        # COMPONENTS
        if 'COMPONENTS' in sheets:
            result['components'] = self._parse_components_data(sheets['COMPONENTS'])

        # SUB_COMPONENTS
        if 'SUB_COMPONENTS' in sheets:
            result['sub_components'] = self._parse_sub_components_data(sheets['SUB_COMPONENTS'])

        # CONNECTIONS
        if 'CONNECTIONS' in sheets:
            result['connections'] = self._parse_connections(sheets['CONNECTIONS'])

        # GROUPS
        if 'GROUPS' in sheets:
            result['groups'] = self._parse_groups(sheets['GROUPS'])

        return result

    def _parse_layers_data(self, df: pd.DataFrame) -> List[Dict]:
        """LAYERS ë°ì´í„° íŒŒì‹±"""
        layers = []
        for _, row in df.iterrows():
            if pd.isna(row.get('ë ˆì´ì–´ID')):
                continue

            layer = {
                'id': row['ë ˆì´ì–´ID'],
                'name': row['ë ˆì´ì–´ëª…'],
                'height_percent': row['ë†’ì´%'],
                'bg_color': row['ë°°ê²½ìƒ‰'],
                'border_color': row.get('í…Œë‘ë¦¬ìƒ‰', 'ê²€ì •')
            }
            layers.append(layer)
        return layers

    def _parse_components_data(self, df: pd.DataFrame) -> List[Dict]:
        """COMPONENTS ë°ì´í„° íŒŒì‹±"""
        components = []
        for _, row in df.iterrows():
            if pd.isna(row.get('ID')):
                continue

            comp = {
                'id': row['ID'],
                'name': row['ì»´í¬ë„ŒíŠ¸ëª…'],
                'layer_id': row['ë ˆì´ì–´ID'],
                'type': row['íƒ€ì…'],
                'width': row['ë„ˆë¹„'],
                'icon': row.get('ì•„ì´ì½˜'),
                'text_size': row.get('í…ìŠ¤íŠ¸í¬ê¸°', 'ì¤‘ê°„')
            }
            components.append(comp)
        return components

    def _parse_sub_components_data(self, df: pd.DataFrame) -> List[Dict]:
        """SUB_COMPONENTS ë°ì´í„° íŒŒì‹±"""
        sub_components = []
        for _, row in df.iterrows():
            if pd.isna(row.get('ë¶€ëª¨ID')):
                continue

            sub = {
                'parent_id': row['ë¶€ëª¨ID'],
                'name': row['ì„œë¸Œì»´í¬ë„ŒíŠ¸ëª…'],
                'order': row['ìˆœì„œ']
            }
            sub_components.append(sub)
        return sub_components


class NestedExcelParser(BaseExcelParser):
    """ê³„ì¸µí˜• ì—‘ì…€ íŒŒì„œ (LAYERS/BOXES/COMPONENTS ê¸°ë°˜)"""

    def __init__(self):
        super().__init__()
        self.excel_version: Optional[str] = None  # 'v5' ë˜ëŠ” 'v6'

    def _detect_version(self, sheets: Dict[str, pd.DataFrame]):
        """ì—‘ì…€ ë²„ì „ ìë™ ê°ì§€ (v5: X%/ë„ˆë¹„% ê¸°ë°˜, v6: í–‰ë²ˆí˜¸ ê¸°ë°˜)"""
        if 'BOXES' in sheets:
            df = sheets['BOXES']
            if 'í–‰ë²ˆí˜¸' in df.columns and 'X%' not in df.columns:
                self.excel_version = 'v6'
            else:
                self.excel_version = 'v5'

    def validate_data(self, sheets: Dict[str, pd.DataFrame]) -> Dict[str, Any]:
        """ê³„ì¸µí˜• ë°ì´í„° ê²€ì¦"""
        if self.errors:
            return self._get_validation_result()

        if not sheets:
            self.errors.append(ERROR_MESSAGES['no_sheets_found'])
            return self._get_validation_result()

        # í•„ìˆ˜ ì‹œíŠ¸ í™•ì¸
        required = ['CONFIG', 'LAYERS', 'BOXES']
        for sheet in required:
            if sheet not in sheets:
                self.errors.append(ERROR_MESSAGES['missing_sheet'].format(sheet_name=sheet))

        if self.errors:
            return self._get_validation_result()

        # ë²„ì „ ê°ì§€
        self._detect_version(sheets)

        # ì •ë³´ ë©”ì‹œì§€
        if self.excel_version == 'v6':
            self.infos.append("âœ… v6.0 ê³„ì¸µí˜• ì—‘ì…€ í˜•ì‹ (í–‰ë²ˆí˜¸ ê¸°ë°˜ ìë™ ë ˆì´ì•„ì›ƒ)")
        else:
            self.infos.append("âœ… v5.0 ê³„ì¸µí˜• ì—‘ì…€ í˜•ì‹ (X%, ë„ˆë¹„% ê¸°ë°˜)")

        # LAYERS ê²€ì¦
        self._validate_layers(sheets.get('LAYERS'))

        # BOXES ê²€ì¦
        self._validate_boxes(sheets.get('BOXES'))

        # COMPONENTS ê²€ì¦ (ì„ íƒì‚¬í•­)
        if 'COMPONENTS' in sheets:
            self._validate_nested_components(sheets['COMPONENTS'])

        # CONNECTIONS ê²€ì¦ (ì„ íƒì‚¬í•­)
        if 'CONNECTIONS' in sheets:
            self._validate_nested_connections(sheets['CONNECTIONS'], sheets)

        # ê°œìˆ˜ ì •ë³´
        self.infos.append(f"ğŸ—‚ï¸ ë ˆì´ì–´: {len(sheets['LAYERS'])}ê°œ")
        self.infos.append(f"ğŸ“¦ ë°•ìŠ¤: {len(sheets['BOXES'])}ê°œ")
        if 'COMPONENTS' in sheets:
            self.infos.append(f"ğŸ“‹ ì»´í¬ë„ŒíŠ¸: {len(sheets['COMPONENTS'])}ê°œ")
        if 'CONNECTIONS' in sheets:
            self.infos.append(f"ğŸ”— ì—°ê²°: {len(sheets['CONNECTIONS'])}ê°œ")

        return self._get_validation_result()

    def _validate_layers(self, df: pd.DataFrame):
        """LAYERS ì‹œíŠ¸ ê²€ì¦"""
        if df is None:
            return

        required_cols = ['ë ˆì´ì–´ID', 'ë ˆì´ì–´ëª…', 'ìˆœì„œ', 'ë°°ê²½ìƒ‰', 'ë†’ì´%']
        for col in required_cols:
            if col not in df.columns:
                self.errors.append(
                    ERROR_MESSAGES['missing_column'].format(
                        sheet_name='LAYERS', column_name=col
                    )
                )

    def _validate_boxes(self, df: pd.DataFrame):
        """BOXES ì‹œíŠ¸ ê²€ì¦"""
        if df is None:
            return

        # v6.0 í•„ìˆ˜ ì»¬ëŸ¼
        if self.excel_version == 'v6':
            required_cols = ['ë°•ìŠ¤ID', 'ë°•ìŠ¤ëª…', 'ë¶€ëª¨ID', 'í–‰ë²ˆí˜¸', 'Y%', 'ë†’ì´%']
        else:
            required_cols = ['ë°•ìŠ¤ID', 'ë°•ìŠ¤ëª…', 'ë¶€ëª¨ID', 'X%', 'Y%', 'ë„ˆë¹„%', 'ë†’ì´%']

        for col in required_cols:
            if col not in df.columns:
                self.errors.append(
                    ERROR_MESSAGES['missing_column'].format(
                        sheet_name='BOXES', column_name=col
                    )
                )

        # ê°œìˆ˜ ê²½ê³ 
        if len(df) > VALIDATION_RULES['max_boxes']:
            self.warnings.append(
                WARNING_MESSAGES['too_many_boxes'].format(
                    count=len(df),
                    max=VALIDATION_RULES['max_boxes']
                )
            )

    def _validate_nested_components(self, df: pd.DataFrame):
        """ê³„ì¸µí˜• COMPONENTS ì‹œíŠ¸ ê²€ì¦"""
        if df is None:
            return

        required_cols = ['ID', 'ì»´í¬ë„ŒíŠ¸ëª…', 'ë¶€ëª¨ID']
        for col in required_cols:
            if col not in df.columns:
                self.errors.append(
                    ERROR_MESSAGES['missing_column'].format(
                        sheet_name='COMPONENTS', column_name=col
                    )
                )

    def _validate_nested_connections(self, df: pd.DataFrame, sheets: Dict[str, pd.DataFrame]):
        """ê³„ì¸µí˜• CONNECTIONS ì‹œíŠ¸ ê²€ì¦"""
        if df is None:
            return

        # ëª¨ë“  ìœ íš¨í•œ ID ìˆ˜ì§‘ (ë°•ìŠ¤ + ì»´í¬ë„ŒíŠ¸)
        valid_ids = set()
        if 'BOXES' in sheets:
            valid_ids.update(sheets['BOXES']['ë°•ìŠ¤ID'].dropna())
        if 'COMPONENTS' in sheets:
            valid_ids.update(sheets['COMPONENTS']['ID'].dropna())

        for idx, row in df.iterrows():
            from_id = row.get('ì¶œë°œID')
            to_id = row.get('ë„ì°©ID')

            if pd.notna(from_id) and from_id not in valid_ids:
                self.warnings.append(f"ì—°ê²° ì¶œë°œID '{from_id}'ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            if pd.notna(to_id) and to_id not in valid_ids:
                self.warnings.append(f"ì—°ê²° ë„ì°©ID '{to_id}'ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

    def parse_to_dict(self, sheets: Dict[str, pd.DataFrame]) -> Dict[str, Any]:
        """ê³„ì¸µí˜• ë°ì´í„°ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        # ë²„ì „ ê°ì§€
        if self.excel_version is None:
            self._detect_version(sheets)

        result = {
            'config': {},
            'layers': [],
            'boxes': [],
            'components': [],
            'connections': [],
            'groups': []
        }

        # CONFIG
        if 'CONFIG' in sheets:
            result['config'] = self._parse_config(sheets['CONFIG'])

        # LAYERS
        if 'LAYERS' in sheets:
            result['layers'] = self._parse_nested_layers(sheets['LAYERS'])

        # BOXES
        if 'BOXES' in sheets:
            result['boxes'] = self._parse_boxes_data(sheets['BOXES'])

        # COMPONENTS
        if 'COMPONENTS' in sheets:
            result['components'] = self._parse_nested_components_data(sheets['COMPONENTS'])

        # CONNECTIONS
        if 'CONNECTIONS' in sheets:
            result['connections'] = self._parse_connections(sheets['CONNECTIONS'])

        # GROUPS
        if 'GROUPS' in sheets:
            result['groups'] = self._parse_groups(sheets['GROUPS'])

        return result

    def _parse_nested_layers(self, df: pd.DataFrame) -> List[Dict]:
        """ê³„ì¸µí˜• LAYERS ë°ì´í„° íŒŒì‹±"""
        layers = []
        for _, row in df.iterrows():
            if pd.isna(row.get('ë ˆì´ì–´ID')):
                continue

            layer = {
                'id': row['ë ˆì´ì–´ID'],
                'name': row.get('ë ˆì´ì–´ëª…', ''),
                'order': row.get('ìˆœì„œ', 1),
                'bg_color': row.get('ë°°ê²½ìƒ‰', 'í°ìƒ‰'),
                'height_percent': row.get('ë†’ì´%', 50)
            }
            layers.append(layer)
        return layers

    def _parse_boxes_data(self, df: pd.DataFrame) -> List[Dict]:
        """BOXES ë°ì´í„° íŒŒì‹± (v5/v6 ìë™ ì²˜ë¦¬)"""
        boxes = []
        for _, row in df.iterrows():
            if pd.isna(row.get('ë°•ìŠ¤ID')):
                continue

            box = {
                'id': row['ë°•ìŠ¤ID'],
                'name': row.get('ë°•ìŠ¤ëª…', ''),
                'parent_id': row.get('ë¶€ëª¨ID'),
                'y_percent': row.get('Y%', 0),
                'height_percent': row.get('ë†’ì´%', 100),
                'bg_color': row.get('ë°°ê²½ìƒ‰', 'í°ìƒ‰'),
                'border_color': row.get('í…Œë‘ë¦¬ìƒ‰', 'íšŒìƒ‰'),
                'font_size': row.get('í°íŠ¸í¬ê¸°', 11)
            }

            # ë²„ì „ë³„ ì¶”ê°€ í•„ë“œ
            if self.excel_version == 'v6':
                box['row_number'] = row.get('í–‰ë²ˆí˜¸', 1)
            else:
                box['x_percent'] = row.get('X%', 0)
                box['width_percent'] = row.get('ë„ˆë¹„%', 100)

            boxes.append(box)
        return boxes

    def _parse_nested_components_data(self, df: pd.DataFrame) -> List[Dict]:
        """ê³„ì¸µí˜• COMPONENTS ë°ì´í„° íŒŒì‹±"""
        components = []
        for _, row in df.iterrows():
            if pd.isna(row.get('ID')):
                continue

            comp = {
                'id': row['ID'],
                'name': row.get('ì»´í¬ë„ŒíŠ¸ëª…', ''),
                'parent_id': row.get('ë¶€ëª¨ID'),
                'y_percent': row.get('Y%', 0),
                'height_percent': row.get('ë†’ì´%', 100),
                'font_size': row.get('í°íŠ¸í¬ê¸°', 10),
                'type': row.get('íƒ€ì…', 'ë‹¨ì¼ë°•ìŠ¤')
            }

            # ë²„ì „ë³„ ì¶”ê°€ í•„ë“œ
            if self.excel_version == 'v6':
                comp['row_number'] = row.get('í–‰ë²ˆí˜¸', 1)
            else:
                comp['x_percent'] = row.get('X%', 0)
                comp['width_percent'] = row.get('ë„ˆë¹„%', 100)

            components.append(comp)
        return components


def create_parser(sheets: Dict[str, pd.DataFrame]) -> BaseExcelParser:
    """ì‹œíŠ¸ êµ¬ì¡°ì— ë”°ë¼ ì ì ˆí•œ íŒŒì„œ ë°˜í™˜"""
    if 'BOXES' in sheets:
        return NestedExcelParser()
    else:
        return ExcelParser()


def detect_excel_type(file) -> str:
    """ì—‘ì…€ íŒŒì¼ íƒ€ì… ê°ì§€ ('nested' ë˜ëŠ” 'flat')"""
    try:
        if hasattr(file, 'read'):
            file_content = io.BytesIO(file.read())
            file.seek(0)
            excel_file = pd.ExcelFile(file_content)
        else:
            excel_file = pd.ExcelFile(file)

        if 'BOXES' in excel_file.sheet_names:
            return 'nested'
        return 'flat'
    except:
        return 'flat'
